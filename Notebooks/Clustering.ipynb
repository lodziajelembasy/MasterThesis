{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import collections\n",
    " \n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, stem=True):\n",
    "    \"\"\" Tokenize text and stem words removing punctuation \"\"\"\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    " \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        tokens = [stemmer.stem(t) for t in tokens]\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_texts(texts, clusters=3):\n",
    "    \"\"\" Transform texts to Tf-Idf coordinates and cluster texts using K-Means \"\"\"\n",
    "    vectorizer = TfidfVectorizer(tokenizer=process_text,\n",
    "                                 stop_words=stopwords.words('english'),\n",
    "                                 max_df=0.5,\n",
    "                                 min_df=0.1,\n",
    "                                 lowercase=True)\n",
    " \n",
    "    tfidf_model = vectorizer.fit_transform(texts)\n",
    "    km_model = KMeans(n_clusters=clusters)\n",
    "    km_model.fit(tfidf_model)\n",
    " \n",
    "    clustering = collections.defaultdict(list)\n",
    " \n",
    "    for idx, label in enumerate(km_model.labels_):\n",
    "        clustering[label].append(idx)\n",
    " \n",
    "    return clustering\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tytuł</th>\n",
       "      <th>Tekst</th>\n",
       "      <th>Eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abba Ojcze</td>\n",
       "      <td>Ty wyzwoliłeś nas Panie  z kajdan i samych sie...</td>\n",
       "      <td>You delivered us from chains and ourselves, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alleluja (Niech zabrzmi Panu)</td>\n",
       "      <td>Alleluja, Alleluja, Alleluja, Alleluja.   Nie...</td>\n",
       "      <td>Alleluia, Alleluia, Alleluia, Alleluia. Let th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alleluja, Alleluja, Amen Amen, Alleluja</td>\n",
       "      <td>Alleluja, Alleluja,  Amen, Amen, Alleluja.   ...</td>\n",
       "      <td>Alleluia, Alleluia, Amen, Amen, Alleluia. Let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blisko, blisko, blisko jesteś</td>\n",
       "      <td>Blisko, blisko, blisko Jesteś Panie mój Blisk...</td>\n",
       "      <td>Close, close, close You are my Lord, Close to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bo góry mogą ustąpić</td>\n",
       "      <td>Bo góry mogą ustąpić i pagórki się zachwiać. ...</td>\n",
       "      <td>Because the mountains can give way and the hil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bo jak śmierć potężna jest miłość</td>\n",
       "      <td>Bo jak śmierć potężna jest Miłość A zazdrość ...</td>\n",
       "      <td>For how death is powerful Love and jealousy ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boże Twa łaska</td>\n",
       "      <td>Boże Twa łaska nad nami jest, Twoja miłość pr...</td>\n",
       "      <td>God, your grace is upon us, your love is comin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Była cicha i piękna jak wiosna</td>\n",
       "      <td>Była cicha i piękna jak wiosna, Żyła prosto, ...</td>\n",
       "      <td>She was as quiet and beautiful as spring, she ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Tytuł  \\\n",
       "0                               Abba Ojcze   \n",
       "1            Alleluja (Niech zabrzmi Panu)   \n",
       "2  Alleluja, Alleluja, Amen Amen, Alleluja   \n",
       "3            Blisko, blisko, blisko jesteś   \n",
       "4                     Bo góry mogą ustąpić   \n",
       "5        Bo jak śmierć potężna jest miłość   \n",
       "6                           Boże Twa łaska   \n",
       "7           Była cicha i piękna jak wiosna   \n",
       "\n",
       "                                               Tekst  \\\n",
       "0  Ty wyzwoliłeś nas Panie  z kajdan i samych sie...   \n",
       "1   Alleluja, Alleluja, Alleluja, Alleluja.   Nie...   \n",
       "2   Alleluja, Alleluja,  Amen, Amen, Alleluja.   ...   \n",
       "3   Blisko, blisko, blisko Jesteś Panie mój Blisk...   \n",
       "4   Bo góry mogą ustąpić i pagórki się zachwiać. ...   \n",
       "5   Bo jak śmierć potężna jest Miłość A zazdrość ...   \n",
       "6   Boże Twa łaska nad nami jest, Twoja miłość pr...   \n",
       "7   Była cicha i piękna jak wiosna, Żyła prosto, ...   \n",
       "\n",
       "                                                 Eng  \n",
       "0  You delivered us from chains and ourselves, an...  \n",
       "1  Alleluia, Alleluia, Alleluia, Alleluia. Let th...  \n",
       "2  Alleluia, Alleluia, Amen, Amen, Alleluia. Let ...  \n",
       "3  Close, close, close You are my Lord, Close to ...  \n",
       "4  Because the mountains can give way and the hil...  \n",
       "5  For how death is powerful Love and jealousy ar...  \n",
       "6  God, your grace is upon us, your love is comin...  \n",
       "7  She was as quiet and beautiful as spring, she ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_eng_songs.csv', header=0, index_col=0)\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'arent', 'becaus', 'befor', 'couldnt', 'didnt', 'doe', 'doesnt', 'dont', 'dure', 'ha', 'hadnt', 'hasnt', 'havent', 'hi', 'isnt', 'mightnt', 'mustnt', 'neednt', 'onc', 'onli', 'ourselv', 'shant', 'shouldnt', 'shouldv', 'thatll', 'themselv', 'thi', 'veri', 'wa', 'wasnt', 'werent', 'whi', 'wont', 'wouldnt', 'youd', 'youll', 'yourselv', 'youv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [4,\n",
      "     5,\n",
      "     9,\n",
      "     31,\n",
      "     57,\n",
      "     59,\n",
      "     60,\n",
      "     61,\n",
      "     62,\n",
      "     63,\n",
      "     66,\n",
      "     73,\n",
      "     77,\n",
      "     80,\n",
      "     83,\n",
      "     87,\n",
      "     91,\n",
      "     96,\n",
      "     100,\n",
      "     119,\n",
      "     122,\n",
      "     123,\n",
      "     125,\n",
      "     127,\n",
      "     157,\n",
      "     161,\n",
      "     165,\n",
      "     174,\n",
      "     185],\n",
      " 1: [0,\n",
      "     1,\n",
      "     3,\n",
      "     8,\n",
      "     10,\n",
      "     11,\n",
      "     12,\n",
      "     13,\n",
      "     15,\n",
      "     16,\n",
      "     18,\n",
      "     20,\n",
      "     21,\n",
      "     22,\n",
      "     23,\n",
      "     24,\n",
      "     25,\n",
      "     26,\n",
      "     28,\n",
      "     37,\n",
      "     41,\n",
      "     43,\n",
      "     44,\n",
      "     46,\n",
      "     49,\n",
      "     51,\n",
      "     54,\n",
      "     64,\n",
      "     65,\n",
      "     67,\n",
      "     68,\n",
      "     70,\n",
      "     71,\n",
      "     72,\n",
      "     74,\n",
      "     76,\n",
      "     79,\n",
      "     82,\n",
      "     85,\n",
      "     86,\n",
      "     88,\n",
      "     89,\n",
      "     90,\n",
      "     98,\n",
      "     102,\n",
      "     107,\n",
      "     110,\n",
      "     113,\n",
      "     114,\n",
      "     115,\n",
      "     116,\n",
      "     120,\n",
      "     121,\n",
      "     129,\n",
      "     131,\n",
      "     134,\n",
      "     135,\n",
      "     136,\n",
      "     144,\n",
      "     145,\n",
      "     147,\n",
      "     148,\n",
      "     149,\n",
      "     151,\n",
      "     153,\n",
      "     154,\n",
      "     155,\n",
      "     156,\n",
      "     159,\n",
      "     163,\n",
      "     164,\n",
      "     167,\n",
      "     169,\n",
      "     170,\n",
      "     172,\n",
      "     173,\n",
      "     175,\n",
      "     176,\n",
      "     178,\n",
      "     180,\n",
      "     181,\n",
      "     183],\n",
      " 2: [2,\n",
      "     7,\n",
      "     14,\n",
      "     19,\n",
      "     29,\n",
      "     30,\n",
      "     32,\n",
      "     33,\n",
      "     34,\n",
      "     35,\n",
      "     36,\n",
      "     38,\n",
      "     39,\n",
      "     40,\n",
      "     42,\n",
      "     45,\n",
      "     47,\n",
      "     48,\n",
      "     50,\n",
      "     52,\n",
      "     53,\n",
      "     55,\n",
      "     58,\n",
      "     69,\n",
      "     78,\n",
      "     92,\n",
      "     93,\n",
      "     94,\n",
      "     95,\n",
      "     97,\n",
      "     99,\n",
      "     101,\n",
      "     105,\n",
      "     106,\n",
      "     109,\n",
      "     112,\n",
      "     117,\n",
      "     118,\n",
      "     124,\n",
      "     128,\n",
      "     130,\n",
      "     138,\n",
      "     139,\n",
      "     142,\n",
      "     143,\n",
      "     158,\n",
      "     166,\n",
      "     171,\n",
      "     182,\n",
      "     184,\n",
      "     186],\n",
      " 3: [6,\n",
      "     17,\n",
      "     27,\n",
      "     56,\n",
      "     75,\n",
      "     81,\n",
      "     84,\n",
      "     103,\n",
      "     104,\n",
      "     108,\n",
      "     111,\n",
      "     126,\n",
      "     132,\n",
      "     133,\n",
      "     137,\n",
      "     140,\n",
      "     141,\n",
      "     146,\n",
      "     150,\n",
      "     152,\n",
      "     160,\n",
      "     162,\n",
      "     168,\n",
      "     177,\n",
      "     179]}\n"
     ]
    }
   ],
   "source": [
    "articles = list(df['Eng'])\n",
    "clusters = cluster_texts(articles, 4)\n",
    "pprint(dict(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She was as quiet and beautiful as spring, she lived simply, just like us. She brought God to the world, and in the world new days were shining with tears. The mother who understands everything is overwhelmed by each one of us. Mother can see good in us, she is with us at all times. Today, the world needs goodness, To anxiety to overcome and evil. You need warmth, what life will goldeniate, You need God, so people, let us not Him, just like Her. The mother who understands everything is overwhelmed by each one of us. Mother can see good in us, she is with us at all times.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[7]['Eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
