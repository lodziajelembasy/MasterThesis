{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize \n",
    "from matplotlib.pyplot import hist, show\n",
    "from collections import Counter\n",
    "import urllib\n",
    "import codecs\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czytania danego dnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the webpage\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "year = str(now.year)\n",
    "month = str(now.month)\n",
    "if len(month) == 1:\n",
    "    month = \"0\" + month\n",
    "day = str(now.day)\n",
    "ymd = year+month+day\n",
    "\n",
    "    \n",
    "#address = \"http://mateusz.pl/czytania/\" + year + \"/\" + ymd + \".html\"\n",
    "address = \"http://mateusz.pl/czytania/2018/20180909.html\"\n",
    "page = requests.get(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing a page\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify()) \n",
    "#Exception handling for more readings\n",
    "try:\n",
    "    section = list(soup.children)[9]\n",
    "    section_content = section.find_all('p')\n",
    "except:\n",
    "    section = soup.find_all('section')[0]\n",
    "    section_content =section.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pierwsze_czytanie = section_content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "ewangelia = section_content[len(section_content)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatyzacja (lemmatisation) \n",
    "Algorytm znajdowania lemmy, formy podstawowej wyrazu w obszarze części mowy którą reprezentuje. Inaczej: wyszukiwanie formy kanonicznej leksemu. W komputerowej analizie języka naturalnego lemmatyzacja jest operacją bardziej precyzyjną niż stemmatyzacja. \n",
    "\n",
    "### Stemmatyzacja (stemming) \n",
    "Sprowadzenie wyrazu reprezentującego dowolną część mowy do stemu, rdzenia postaci źródłowej, najczęściej rzeczownika, bądź niekiedy nawet sekwencji znaków nie mającej samodzielnego znaczenia w języku naturalnym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_stops = codecs.open(\"polishStopWords\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = polish_stops.read().split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "milosc = codecs.open(\"milosc\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "milujcie = codecs.open(\"milujcie\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "milujcie_sent = milujcie.read().split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = \"\"\n",
    "for sentence in milujcie_sent:\n",
    "    song = song + sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = milosc.read()\n",
    "#text = song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "lower_tokens = [t.lower() for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain alphabetic words: alpha_only\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all stop words: no_stops\n",
    "no_stops = [t for t in alpha_only if t not in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "bow = Counter(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('czyńcie', 3),\n",
       " ('należy', 3),\n",
       " ('wdzięczność', 3),\n",
       " ('grzesznicy', 3),\n",
       " ('będziecie', 3),\n",
       " ('miłujcie', 2),\n",
       " ('waszych', 2),\n",
       " ('nieprzyjaciół', 2),\n",
       " ('zwrotu', 2),\n",
       " ('miłują', 2),\n",
       " ('jakaż', 2),\n",
       " ('czynią', 2),\n",
       " ('samo', 2),\n",
       " ('powiadam', 1),\n",
       " ('słuchacie', 1),\n",
       " ('nienawidzą', 1),\n",
       " ('błogosławcie', 1),\n",
       " ('przeklinają', 1),\n",
       " ('módlcie', 1),\n",
       " ('oczerniają', 1)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milosc.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedReader.close>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milujcie.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
