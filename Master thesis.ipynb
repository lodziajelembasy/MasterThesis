{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize \n",
    "from matplotlib.pyplot import hist, show\n",
    "from collections import Counter\n",
    "import urllib\n",
    "import codecs\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Czytania danego dnia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the webpage\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "year = str(now.year)\n",
    "month = str(now.month)\n",
    "if len(month) == 1:\n",
    "    month = \"0\" + month\n",
    "day = str(now.day)\n",
    "ymd = year+month+day\n",
    "address = \"http://mateusz.pl/czytania/\" + year + \"/\" + ymd + \".html\"\n",
    "page = requests.get(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatyzacja (lemmatisation) \n",
    "Algorytm znajdowania lemmy, formy podstawowej wyrazu w obszarze części mowy którą reprezentuje. Inaczej: wyszukiwanie formy kanonicznej leksemu. W komputerowej analizie języka naturalnego lemmatyzacja jest operacją bardziej precyzyjną niż stemmatyzacja. \n",
    "\n",
    "### Stemmatyzacja (stemming) \n",
    "Sprowadzenie wyrazu reprezentującego dowolną część mowy do stemu, rdzenia postaci źródłowej, najczęściej rzeczownika, bądź niekiedy nawet sekwencji znaków nie mającej samodzielnego znaczenia w języku naturalnym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_stops = codecs.open(\"polishStopWords\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = polish_stops.read().split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "milosc = codecs.open(\"milosc\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "milujcie = codecs.open(\"milujcie\",'r','utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "milujcie_sent = milujcie.read().split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "song = \"\"\n",
    "for sentence in milujcie_sent:\n",
    "    song = song + sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = milosc.read()\n",
    "#text = song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "lower_tokens = [t.lower() for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain alphabetic words: alpha_only\n",
    "alpha_only = [t for t in lower_tokens if t.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all stop words: no_stops\n",
    "no_stops = [t for t in alpha_only if t not in ps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "bow = Counter(no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('miłość', 9),\n",
       " ('bym', 4),\n",
       " ('miał', 4),\n",
       " ('gdybym', 3),\n",
       " ('miłości', 3),\n",
       " ('szuka', 2),\n",
       " ('unosi', 2),\n",
       " ('miłujcie', 1),\n",
       " ('wzajemnie', 1),\n",
       " ('umiłowałem', 1),\n",
       " ('mówił', 1),\n",
       " ('językami', 1),\n",
       " ('ludzi', 1),\n",
       " ('aniołów', 1),\n",
       " ('miałstałbym', 1),\n",
       " ('miedź', 1),\n",
       " ('brzęcząca', 1),\n",
       " ('cymbał', 1),\n",
       " ('brzmiący', 1),\n",
       " ('dar', 1)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
